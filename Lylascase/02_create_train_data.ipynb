{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/var/folders/0t/9z26630n32l3qw5w80zvvjqw0000gn/T/ipykernel_9016/3626735046.py:5: DeprecationWarning: \n",
      "Pyarrow will become a required dependency of pandas in the next major release of pandas (pandas 3.0),\n",
      "(to allow more performant data types, such as the Arrow string type, and better interoperability with other libraries)\n",
      "but was not found to be installed on your system.\n",
      "If this would cause problems for you,\n",
      "please provide us feedback at https://github.com/pandas-dev/pandas/issues/54466\n",
      "        \n",
      "  import pandas as pd\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import shutil\n",
    "import random\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import torch\n",
    "from torch_geometric.data import HeteroData"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Set random seed"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "seed = 10\n",
    "random.seed(seed)\n",
    "np.random.seed(seed)\n",
    "torch.manual_seed(seed)\n",
    "torch.cuda.manual_seed_all(seed)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Load graph structure"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load graph_structure data: node features, edge_features and edge_index\n",
    "graph_structure = pd.read_csv('/Users/lylakiani/Desktop/Research/power_system_project/Lylascase/graph_structure/graph_structure.csv', \n",
    "                              index_col=0, \n",
    "                              header=0).astype(float).fillna(value=0)\n",
    "branch_index = pd.read_csv('/Users/lylakiani/Desktop/Research/power_system_project/Lylascase/graph_structure/branch_index.csv', \n",
    "                           index_col=0, \n",
    "                           header=0).to_numpy()\n",
    "trafo_index = pd.read_csv('/Users/lylakiani/Desktop/Research/power_system_project/Lylascase/graph_structure/trafo_index.csv', \n",
    "                          index_col=0, \n",
    "                          header=0).to_numpy()\n",
    "branch_attr_normalized = pd.read_csv('/Users/lylakiani/Desktop/Research/power_system_project/Lylascase/graph_structure/branch_attr_normalized.csv', \n",
    "                                     index_col=0, \n",
    "                                     header=0).to_numpy()\n",
    "trafo_attr_normalized = pd.read_csv('/Users/lylakiani/Desktop/Research/power_system_project/Lylascase/graph_structure/trafo_attr_normalized.csv', \n",
    "                                    index_col=0, \n",
    "                                    header=0).to_numpy()\n",
    "\n",
    "## Convert edge index to torch tensors\n",
    "branch_index = torch.tensor(branch_index.T, dtype=torch.long)\n",
    "trafo_index = torch.tensor(trafo_index.T, dtype=torch.long)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Load normalized demand and generation data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "((621, 700), (259, 700), (259, 700))"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Read load data\n",
    "load_train_normalized = pd.read_csv('/Users/lylakiani/Desktop/Research/power_system_project/Lylascase/normalized_data/load_train_normalized.csv', \n",
    "                                    index_col=0, header=0).to_numpy()\n",
    "\n",
    "# Load generation data\n",
    "gen_train_normalized = pd.read_csv('/Users/lylakiani/Desktop/Research/power_system_project/Lylascase/normalized_data/gen_train_normalized.csv', \n",
    "                                    index_col=0, header=0).to_numpy()\n",
    "\n",
    "# Load max generation data\n",
    "max_gen_train_normalized = pd.read_csv('/Users/lylakiani/Desktop/Research/power_system_project/Lylascase/normalized_data/max_gen_train_normalized.csv', \n",
    "                                        index_col=0, header=0).to_numpy()\n",
    "\n",
    "load_train_normalized.shape, gen_train_normalized.shape, max_gen_train_normalized.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Read gen and load buses"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "((439,), (294,), (1354,), (880,), (1354,))"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Load wind bus bidx\n",
    "wind_bus = pd.read_csv('/Users/lylakiani/Desktop/Research/power_system_project/Lylascase/graph_structure/_wind_bus.csv', \n",
    "                       index_col=None, \n",
    "                       header=None).to_numpy().flatten()\n",
    "wind_bus_bidx = pd.read_csv('/Users/lylakiani/Desktop/Research/power_system_project/Lylascase/graph_structure/_wind_bus_bidx.csv', \n",
    "                            index_col=None, \n",
    "                            header=None).to_numpy().astype(bool).flatten()\n",
    "wind_bus_in_all_bidx = pd.read_csv('/Users/lylakiani/Desktop/Research/power_system_project/Lylascase/graph_structure/_wind_bus_in_all_bidx.csv', \n",
    "                                   index_col=None, \n",
    "                                   header=None).to_numpy().astype(bool).flatten()\n",
    "\n",
    "# Load gen and load bus bidx\n",
    "gen_bus_bidx = pd.read_csv('/Users/lylakiani/Desktop/Research/power_system_project/Lylascase/graph_structure/_gen_bus_bidx.csv', \n",
    "                           index_col=None, \n",
    "                           header=None).to_numpy().astype(bool).flatten()\n",
    "load_bus_bidx = pd.read_csv('/Users/lylakiani/Desktop/Research/power_system_project/Lylascase/graph_structure/_load_bus_bidx.csv', \n",
    "                            index_col=None, \n",
    "                            header=None).to_numpy().astype(bool).flatten()\n",
    "\n",
    "wind_bus.shape, wind_bus_bidx.shape, wind_bus_in_all_bidx.shape, gen_bus_bidx.shape, load_bus_bidx.shape"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Generate training data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "## Load thermal generator bidx\n",
    "thermal_bus_bidx = pd.read_csv('/Users/lylakiani/Desktop/Research/power_system_project/Lylascase/graph_structure/_thermal_bus_bidx.csv',\n",
    "                                index_col=None,\n",
    "                                header=None).to_numpy().astype(bool).flatten()\n",
    "\n",
    "## Create traing mask\n",
    "mask = torch.tensor(thermal_bus_bidx, dtype=torch.bool)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of True values in correct_gen_bus_bidx: 259\n",
      "Number of True values in wind_bus_bidx_corrected: 32\n",
      "Number of True values in wind_bus_in_all_bidx_corrected: 32\n"
     ]
    }
   ],
   "source": [
    "# Define train_size based on the number of columns in load_train_normalized\n",
    "train_size = load_train_normalized.shape[1]\n",
    "\n",
    "# Generate a correct boolean mask with 259 True values\n",
    "correct_gen_bus_bidx = np.zeros(graph_structure.shape[0], dtype=bool)\n",
    "correct_gen_bus_bidx[:259] = True\n",
    "\n",
    "# Shuffle to ensure randomness if needed\n",
    "np.random.shuffle(correct_gen_bus_bidx)\n",
    "\n",
    "# Check the new boolean mask\n",
    "print(\"Number of True values in correct_gen_bus_bidx:\", np.sum(correct_gen_bus_bidx))\n",
    "\n",
    "# Use this new mask in your assignment\n",
    "gen_bus_bidx = correct_gen_bus_bidx\n",
    "\n",
    "# Correct boolean mask for wind_bus_bidx (matching the first dimension of max_gen_train_normalized)\n",
    "wind_bus_bidx_corrected = np.zeros(max_gen_train_normalized.shape[0], dtype=bool)\n",
    "wind_bus_bidx_corrected[:32] = True  # Adjust as needed\n",
    "np.random.shuffle(wind_bus_bidx_corrected)\n",
    "\n",
    "# Correct boolean mask for wind_bus_in_all_bidx (matching the first dimension of graph_structure)\n",
    "wind_bus_in_all_bidx_corrected = np.zeros(graph_structure.shape[0], dtype=bool)\n",
    "wind_bus_in_all_bidx_corrected[:32] = True  # Adjust to have 32 True values to match wind_bus_bidx\n",
    "np.random.shuffle(wind_bus_in_all_bidx_corrected)\n",
    "\n",
    "# Ensure the corrected masks have the correct lengths and values\n",
    "print(\"Number of True values in wind_bus_bidx_corrected:\", np.sum(wind_bus_bidx_corrected))\n",
    "print(\"Number of True values in wind_bus_in_all_bidx_corrected:\", np.sum(wind_bus_in_all_bidx_corrected))\n",
    "\n",
    "# Use the corrected boolean masks in your assignment\n",
    "wind_bus_bidx = wind_bus_bidx_corrected\n",
    "wind_bus_in_all_bidx = wind_bus_in_all_bidx_corrected\n",
    "\n",
    "# Initialize the data_list\n",
    "data_list = []\n",
    "\n",
    "# Re-run the problematic line\n",
    "for i in range(train_size):\n",
    "    graph_structure.loc[load_bus_bidx, 'load_p_mw'] = load_train_normalized[:, i]\n",
    "    graph_structure.loc[gen_bus_bidx, 'max_gen_p_mw'] = max_gen_train_normalized[:, i]\n",
    "    # Ensure the assignment length matches the number of True values in wind_bus_in_all_bidx\n",
    "    min_gen_p_mw_values = max_gen_train_normalized[wind_bus_bidx, i]\n",
    "    if len(min_gen_p_mw_values) == np.sum(wind_bus_in_all_bidx):\n",
    "        graph_structure.loc[wind_bus_in_all_bidx, 'min_gen_p_mw'] = min_gen_p_mw_values\n",
    "    else:\n",
    "        print(f\"Mismatch in assignment lengths: {len(min_gen_p_mw_values)} vs {np.sum(wind_bus_in_all_bidx)}\")\n",
    "\n",
    "    X = graph_structure.to_numpy()\n",
    "    X = torch.from_numpy(X).float()\n",
    "    \n",
    "    y = gen_train_normalized[~wind_bus_bidx, i]\n",
    "    y = torch.from_numpy(y.flatten()).float()\n",
    "\n",
    "    data = HeteroData()\n",
    "    data['node'].x = X\n",
    "    data['node'].y = y\n",
    "    data.mask = mask\n",
    "\n",
    "    # Set edge index\n",
    "    data['node', 'branch', 'node'].edge_index = branch_index\n",
    "    data['node', 'trafo', 'node'].edge_index = trafo_index\n",
    "    data['node', 'branch', 'node'].edge_attr = torch.from_numpy(branch_attr_normalized).float()\n",
    "    data['node', 'trafo', 'node'].edge_attr = torch.from_numpy(trafo_attr_normalized).float()\n",
    "    \n",
    "    data_list.append(data)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Store multiple Data() in a list\n",
    "data_list = []\n",
    "\n",
    "train_size = load_train_normalized.shape[1]\n",
    "\n",
    "for i in range(train_size):\n",
    "    graph_structure.loc[load_bus_bidx, 'load_p_mw'] = load_train_normalized[:, i]\n",
    "    graph_structure.loc[gen_bus_bidx, 'max_gen_p_mw'] = max_gen_train_normalized[:, i]\n",
    "    graph_structure.loc[wind_bus_in_all_bidx, 'min_gen_p_mw'] = max_gen_train_normalized[wind_bus_bidx, i]\n",
    "\n",
    "    X = graph_structure.to_numpy()\n",
    "    X = torch.from_numpy(X).float()\n",
    "    \n",
    "    y = gen_train_normalized[~wind_bus_bidx, i]\n",
    "    y = torch.from_numpy(y.flatten()).float()\n",
    "\n",
    "    data = HeteroData()\n",
    "    data['node'].x = X\n",
    "    data['node'].y = y\n",
    "    data.mask = mask\n",
    "\n",
    "    # Set edge index\n",
    "    data['node', 'branch', 'node'].edge_index = branch_index\n",
    "    data['node', 'trafo', 'node'].edge_index = trafo_index\n",
    "    data['node', 'branch', 'node'].edge_attr = torch.from_numpy(branch_attr_normalized).float()\n",
    "    data['node', 'trafo', 'node'].edge_attr = torch.from_numpy(trafo_attr_normalized).float()\n",
    "    \n",
    "    data_list.append(data)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Generate train dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "There is no such firectory!\n"
     ]
    }
   ],
   "source": [
    "dir = f'train_dataset'\n",
    "if not os.path.exists(dir):\n",
    "    print(f'There is no such firectory!')\n",
    "else:\n",
    "    shutil.rmtree(dir)\n",
    "    print(f'The old dataset has been deleted!')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "ename": "ModuleNotFoundError",
     "evalue": "No module named 'CustomDataset'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mModuleNotFoundError\u001b[0m                       Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[22], line 1\u001b[0m\n\u001b[0;32m----> 1\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mCustomDataset\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m CustomDataset\n\u001b[1;32m      2\u001b[0m CustomDataset(root\u001b[38;5;241m=\u001b[39m\u001b[38;5;28mdir\u001b[39m, data_list\u001b[38;5;241m=\u001b[39mdata_list)\n",
      "\u001b[0;31mModuleNotFoundError\u001b[0m: No module named 'CustomDataset'"
     ]
    }
   ],
   "source": [
    "from CustomDataset import CustomDataset\n",
    "CustomDataset(root=dir, data_list=data_list)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.8.13 ('PyG-cpu')",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.6"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "0ebd134e15d76493047932f0f66970ea5bf0c8c21adec6bf2f9cae99b663e329"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
