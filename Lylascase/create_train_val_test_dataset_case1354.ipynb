{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/var/folders/0t/9z26630n32l3qw5w80zvvjqw0000gn/T/ipykernel_14728/1010190927.py:2: DeprecationWarning: \n",
      "Pyarrow will become a required dependency of pandas in the next major release of pandas (pandas 3.0),\n",
      "(to allow more performant data types, such as the Arrow string type, and better interoperability with other libraries)\n",
      "but was not found to be installed on your system.\n",
      "If this would cause problems for you,\n",
      "please provide us feedback at https://github.com/pandas-dev/pandas/issues/54466\n",
      "        \n",
      "  import pandas as pd\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "import seaborn as sns\n",
    "\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "from torch.functional import F\n",
    "from torch_geometric.nn import GCNConv, GATConv\n",
    "from torch_geometric.data import Data, HeteroData\n",
    "from torch_geometric.loader import DataListLoader, DataLoader\n",
    "from torch_geometric.utils.convert import to_networkx\n",
    "import networkx as nx\n",
    "\n",
    "from sklearn.preprocessing import MinMaxScaler"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(1354, 8) (1751, 2) (240, 2) (1751, 3) (240, 5)\n"
     ]
    }
   ],
   "source": [
    "# Load network data: node features, edge_features and edge_index\n",
    "node_features = pd.read_csv('network/node_features.csv', index_col=0, header=0)\n",
    "node_features = node_features.astype(np.float64).fillna(value=0)\n",
    "branch_index = pd.read_csv('network/branch_index.csv', index_col=0, header=0)\n",
    "trafo_index = pd.read_csv('network/trafo_index.csv', index_col=0, header=0)\n",
    "branch_attr = pd.read_csv('network/branch_attr.csv', index_col=0, header=0)\n",
    "trafo_attr = pd.read_csv('network/trafo_attr.csv', index_col=0, header=0)\n",
    "\n",
    "# Display the shapes\n",
    "print(node_features.shape, branch_index.shape, trafo_index.shape, branch_attr.shape, trafo_attr.shape)\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Convert indices to torch tensors\n",
    "branch_index = torch.tensor(branch_index.to_numpy().T, dtype=torch.long)\n",
    "trafo_index = torch.tensor(trafo_index.to_numpy().T, dtype=torch.long)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(621, 1000)"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Load synthetic 'p_mw' at load buses\n",
    "p_load_data = pd.read_csv('synthetic_data/p_load_data.csv', index_col=0, header=0)\n",
    "p_load_data.shape\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(259, 1000)"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Load synthetic 'p_mw' at generator buses\n",
    "p_gen_data = pd.read_csv('synthetic_data/p_gen_data.csv', index_col=0, header=0)\n",
    "p_gen_data.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(1354, 1000)"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Load scaled 'p_mw' at all buses\n",
    "p_bus_data = pd.read_csv('synthetic_data/p_bus_data.csv', index_col=0, header=0)\n",
    "p_bus_data.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(1000, 1)"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "p_slack_max_data = pd.read_csv('synthetic_data/p_slack_max_data.csv', index_col=0, header=0)\n",
    "p_slack_max_data.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "## All bus\n",
    "bus = np.arange(node_features.shape[0])\n",
    "\n",
    "## All gen bus\n",
    "gen_bus = pd.read_csv('zones/re_gen_bus.csv', \n",
    "                      index_col=None, \n",
    "                      header=None).to_numpy()\n",
    "gen_bus = gen_bus.reshape((-1)) - 1\n",
    "# Gen bus mask\n",
    "gen_no = np.isin(bus, gen_bus)\n",
    "\n",
    "# All load bus\n",
    "load_bus = pd.read_csv('zones/load_bus.csv', \n",
    "                       index_col=None, \n",
    "                       header=None).to_numpy()\n",
    "load_bus = load_bus.reshape((-1)) - 1\n",
    "# Load bus mask\n",
    "load_no = np.isin(bus, load_bus)\n",
    "\n",
    "# Wind bus\n",
    "re_gen_bus = pd.read_csv('zones/wind_bus.csv', \n",
    "                         index_col=None, \n",
    "                         header=None).to_numpy()\n",
    "re_gen_bus = re_gen_bus.reshape((-1)) - 1\n",
    "# Wind bus mask\n",
    "re_gen_no = np.isin(gen_bus, re_gen_bus)\n",
    "not_re_gen_no = ~re_gen_no"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "((207,), (259,), (259,), (1354,), (1354,))"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "re_gen_bus.shape, re_gen_no.shape, not_re_gen_no.shape, gen_no.shape, load_no.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Total number of buses: 1354\n",
      "Number of valid load buses: 91\n",
      "Number of valid wind generation buses: 23\n",
      "Shape of p_load_data: (621, 1000)\n",
      "Shape of p_gen_data: (259, 1000)\n"
     ]
    }
   ],
   "source": [
    "\n",
    "# Define bus arrays\n",
    "bus = np.arange(node_features.shape[0])\n",
    "\n",
    "# Load and generation buses\n",
    "load_bus = pd.read_csv('zones/load_bus.csv', index_col=None, header=None).to_numpy().reshape((-1)) - 1\n",
    "gen_bus = pd.read_csv('zones/re_gen_bus.csv', index_col=None, header=None).to_numpy().reshape((-1)) - 1\n",
    "re_gen_bus = pd.read_csv('zones/wind_bus.csv', index_col=None, header=None).to_numpy().reshape((-1)) - 1\n",
    "\n",
    "# Ensure load_bus and re_gen_bus are valid indices in node_features\n",
    "valid_load_indices = [idx for idx in load_bus if idx in node_features.index]\n",
    "valid_re_gen_indices = [idx for idx in re_gen_bus if idx in node_features.index]\n",
    "\n",
    "# Verify shapes of masks and data\n",
    "print(f\"Total number of buses: {len(bus)}\")\n",
    "print(f\"Number of valid load buses: {len(valid_load_indices)}\")\n",
    "print(f\"Number of valid wind generation buses: {len(valid_re_gen_indices)}\")\n",
    "print(f\"Shape of p_load_data: {p_load_data.shape}\")\n",
    "print(f\"Shape of p_gen_data: {p_gen_data.shape}\")\n",
    "\n",
    "# Store multiple Data() in a list\n",
    "data_list = []\n",
    "\n",
    "for i in range(p_load_data.shape[1]):\n",
    "    # Ensure we use only the relevant portion of p_load_data\n",
    "    load_values = p_load_data.iloc[:len(valid_load_indices), i].values\n",
    "    if len(valid_load_indices) != len(load_values):\n",
    "        raise ValueError(f\"Mismatch in lengths: valid_load_indices={len(valid_load_indices)}, load_values={len(load_values)}\")\n",
    "    node_features.loc[valid_load_indices, 'load_p_mw'] = load_values\n",
    "\n",
    "    # Ensure the correct length of values for re_gen_no mask\n",
    "    re_gen_values = p_gen_data.iloc[:len(valid_re_gen_indices), i].values\n",
    "    if len(re_gen_values) != len(valid_re_gen_indices):\n",
    "        raise ValueError(f\"Mismatch in lengths: re_gen_values={len(re_gen_values)}, valid_re_gen_indices={len(valid_re_gen_indices)}\")\n",
    "    node_features.loc[valid_re_gen_indices, 'max_gen_p_mw'] = re_gen_values\n",
    "    node_features.loc[valid_re_gen_indices, 'min_gen_p_mw'] = re_gen_values\n",
    "\n",
    "    # Set max_p_mw at the slack bus\n",
    "    node_features.loc[271, 'max_gen_p_mw'] = p_slack_max_data.iloc[i].values\n",
    "\n",
    "    # Convert features and targets to tensors\n",
    "    X = torch.from_numpy(node_features.to_numpy()).float()\n",
    "    y = torch.from_numpy(p_bus_data.iloc[:, i].to_numpy().reshape((-1))).float()\n",
    "\n",
    "    # Create HeteroData object\n",
    "    data = HeteroData()\n",
    "    data['node'].x = X\n",
    "    data['node'].y = y\n",
    "\n",
    "    # Set edge index and attributes\n",
    "    data['node', 'branch', 'node'].edge_index = branch_index\n",
    "    data['node', 'branch', 'node'].edge_attr = torch.from_numpy(branch_attr.to_numpy()).float()\n",
    "    data['node', 'trafo', 'node'].edge_index = trafo_index\n",
    "    data['node', 'trafo', 'node'].edge_attr = torch.from_numpy(trafo_attr.to_numpy()).float()\n",
    "\n",
    "    data_list.append(data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "## Save train and test dataset\n",
    "train_size = int(0.7*len(data_list))\n",
    "val_size = int(0.1*len(data_list))\n",
    "test_size = int(0.2*len(data_list))\n",
    "\n",
    "# Create PyTorch Geometric DataLoader()\n",
    "batch_size = 1\n",
    "train_data_loader = DataLoader(dataset=data_list[:train_size], batch_size=batch_size, shuffle=False)\n",
    "val_data_loader = DataLoader(dataset=data_list[train_size:train_size+val_size], batch_size=batch_size, shuffle=False)\n",
    "test_data_loader = DataLoader(dataset=data_list[-test_size:], batch_size=batch_size, shuffle=False)\n",
    "\n",
    "# Save train and test datasets\n",
    "torch.save(train_data_loader, 'train_test_dataset/node_prediction_train_dataset.pt')\n",
    "torch.save(val_data_loader, 'train_test_dataset/node_prediction_val_dataset.pt')\n",
    "torch.save(test_data_loader, 'train_test_dataset/node_prediction_test_dataset.pt')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
